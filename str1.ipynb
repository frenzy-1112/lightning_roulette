{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c6782a8-47e1-4977-b6b0-8d7b18b64c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pytz  # Import pytz to handle time zones\n",
    "\n",
    "# Load saved models and scaler\n",
    "deep_model = load_model('deep_model.h5')\n",
    "rf_model = joblib.load('rf_model.pkl')\n",
    "xgb_model = joblib.load('xgb_model.pkl')\n",
    "lr_model = joblib.load('lr_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Helper functions for feature extraction\n",
    "def get_column_from_spin(spin):\n",
    "    if (spin - 1) % 3 == 0:\n",
    "        return 1  # 1st column\n",
    "    elif (spin - 2) % 3 == 0:\n",
    "        return 2  # 2nd column\n",
    "    else:\n",
    "        return 3  # 3rd column\n",
    "\n",
    "def extract_categorical_features(number):\n",
    "    features = {}\n",
    "    features['even_odd'] = 1 if number % 2 == 0 else 0  # 1 = Even, 0 = Odd\n",
    "    features['high_low'] = 1 if 19 <= number <= 36 else 0  # 1 = High, 0 = Low (1-18)\n",
    "    features['dozen'] = (number - 1) // 12 + 1  # 1 = 1-12, 2 = 13-24, 3 = 25-36\n",
    "    return features\n",
    "\n",
    "def extract_previous_spins_features(data, sequence_length=10):\n",
    "    features = {}\n",
    "    if len(data) >= sequence_length:\n",
    "        last_n_spins = data[-sequence_length:]\n",
    "        features['rolling_mean'] = np.mean(last_n_spins)\n",
    "        features['rolling_std'] = np.std(last_n_spins)\n",
    "        features['rolling_min'] = np.min(last_n_spins)\n",
    "        features['rolling_max'] = np.max(last_n_spins)\n",
    "    return features\n",
    "\n",
    "def create_features(df, sequence_length=10):\n",
    "    categorical_features = df['result'].apply(extract_categorical_features).apply(pd.Series)\n",
    "    \n",
    "    # Create rolling features manually\n",
    "    rolling_features = []\n",
    "    for i in range(sequence_length, len(df)):\n",
    "        spins_sequence = df['result'].iloc[i-sequence_length:i]\n",
    "        features = extract_previous_spins_features(spins_sequence, sequence_length)\n",
    "        rolling_features.append(features)\n",
    "    \n",
    "    rolling_features_df = pd.DataFrame(rolling_features)\n",
    "    \n",
    "    # Merge categorical and rolling features\n",
    "    df_features = pd.concat([df.iloc[sequence_length:], categorical_features, rolling_features_df], axis=1)\n",
    "    \n",
    "    # Drop NaN values (shouldn't be any after the rolling features extraction)\n",
    "    df_features = df_features.dropna()\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Function to fetch data from the API\n",
    "async def fetch_data():\n",
    "    url = \"https://api.tracksino.com/lightningroulette_history\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer 35423482-f852-453c-97a4-4f5763f4796f\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"Origin\": \"https://tracksino.com\"\n",
    "    }\n",
    "    params = {\n",
    "        \"sort_by\": \"\",\n",
    "        \"sort_desc\": \"false\",\n",
    "        \"per_page\": 100,  # 100 results per page\n",
    "        \"period\": \"1month\",\n",
    "        \"table_id\": 4,\n",
    "        \"page\": 1  # Fetch only page 1\n",
    "    }\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url, headers=headers, params=params) as response:\n",
    "            if response.status == 200:\n",
    "                data = await response.json()\n",
    "                return [{'when': entry['when'], 'result': entry['result']} for entry in data.get('data', [])]\n",
    "            else:\n",
    "                print(f\"Error fetching data: {response.status}\")\n",
    "                return []\n",
    "\n",
    "# Function to fetch and process the data\n",
    "async def get_processed_data():\n",
    "    data = await fetch_data()\n",
    "    if data:\n",
    "        # Convert the fetched data into a DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # We do not need to reverse the data, as the most recent spin is already the first row.\n",
    "        df['Datetime'] = pd.to_datetime(df['when'], unit='s')\n",
    "        \n",
    "        # Convert to IST (Indian Standard Time)\n",
    "        df['Datetime'] = df['Datetime'].dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "        \n",
    "        df['Hour'] = df['Datetime'].dt.hour\n",
    "        df['Minute'] = df['Datetime'].dt.minute\n",
    "        df['Second'] = df['Datetime'].dt.second\n",
    "        df['Weekday'] = df['Datetime'].dt.weekday\n",
    "        df['Month'] = df['Datetime'].dt.month\n",
    "        df['Column'] = df['result'].apply(get_column_from_spin)\n",
    "        df['Column 11th Spin'] = df['Column'].shift(-10)\n",
    "        df = df.dropna(subset=['Column 11th Spin'])\n",
    "\n",
    "        # Create a column with formatted timestamp (IST)\n",
    "        df['Formatted Time'] = df['Datetime'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "        df_features = create_features(df)\n",
    "        X_input = df_features[['result', 'Hour', 'Minute', 'Second', 'Weekday', 'Month', \n",
    "                               'even_odd', 'high_low', 'dozen', \n",
    "                               'rolling_mean', 'rolling_std', 'rolling_min', 'rolling_max']]\n",
    "        X_input_scaled = scaler.transform(X_input)\n",
    "        \n",
    "        return df, X_input_scaled  # Return the data for further processing\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Streamlit interface\n",
    "st.title(\"Lightning Roulette Prediction\")\n",
    "\n",
    "# Add a button to trigger prediction\n",
    "if st.button('Get Prediction'):\n",
    "    # Fetch the data and make predictions\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    df, X_input_scaled = loop.run_until_complete(get_processed_data())\n",
    "\n",
    "    if df is not None and X_input_scaled is not None:\n",
    "        # Display the last 10 results (most recent spin first)\n",
    "        last_10_results = df[['Formatted Time', 'result']].head(10)  # The API already returns the most recent first\n",
    "        st.write(\"Latest 10 Results (Most Recent First in IST):\")\n",
    "        st.dataframe(last_10_results)\n",
    "\n",
    "        # Predict using the deep learning model\n",
    "        dl_probs = deep_model.predict(X_input_scaled)\n",
    "        rf_probs = rf_model.predict_proba(X_input_scaled)\n",
    "        xgb_probs = xgb_model.predict_proba(X_input_scaled)\n",
    "        lr_probs = lr_model.predict_proba(X_input_scaled)\n",
    "\n",
    "        # Combine the probabilities using soft voting (average)\n",
    "        avg_probs = (dl_probs + rf_probs + xgb_probs + lr_probs) / 4\n",
    "\n",
    "        # Get the top 2 predictions\n",
    "        top_2_predictions = np.argsort(avg_probs, axis=1)[:, -2:]  # Get indices of top 2 predictions\n",
    "\n",
    "        # Convert to 1-indexed labels\n",
    "        top_2_predictions = top_2_predictions + 1\n",
    "\n",
    "        # Column Mapping\n",
    "        column_mapping = {1: '1st Column', 2: '2nd Column', 3: '3rd Column'}\n",
    "        top_2_mapped = [column_mapping[pred] for pred in top_2_predictions[0]]\n",
    "\n",
    "        st.write(f\"Predicted Top 2 Columns for the 11th Spin: {', '.join(top_2_mapped)}\")\n",
    "    else:\n",
    "        st.write(\"Error fetching or processing data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1030cea-1f01-4ad6-bc66-f8a9a6eec6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
