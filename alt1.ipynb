{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5035dbba-8990-404e-8cb3-856eb29b9b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.1789 - val_accuracy: 0.9945 - val_loss: 0.0167\n",
      "Epoch 2/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9909 - loss: 0.0254 - val_accuracy: 0.9948 - val_loss: 0.0164\n",
      "Epoch 3/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9928 - loss: 0.0210 - val_accuracy: 0.9948 - val_loss: 0.0160\n",
      "Epoch 4/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9936 - loss: 0.0190 - val_accuracy: 0.9921 - val_loss: 0.0163\n",
      "Epoch 5/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9933 - loss: 0.0196 - val_accuracy: 0.9948 - val_loss: 0.0160\n",
      "Epoch 6/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9939 - loss: 0.0181 - val_accuracy: 0.9949 - val_loss: 0.0150\n",
      "Epoch 7/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9936 - loss: 0.0187 - val_accuracy: 0.9949 - val_loss: 0.0148\n",
      "Epoch 8/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9936 - loss: 0.0185 - val_accuracy: 0.9948 - val_loss: 0.0159\n",
      "Epoch 9/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9940 - loss: 0.0177 - val_accuracy: 0.9949 - val_loss: 0.0148\n",
      "Epoch 10/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0172 - val_accuracy: 0.9948 - val_loss: 0.0146\n",
      "Epoch 11/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0173 - val_accuracy: 0.9949 - val_loss: 0.0146\n",
      "Epoch 12/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0173 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 13/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0173 - val_accuracy: 0.9949 - val_loss: 0.0146\n",
      "Epoch 14/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0170 - val_accuracy: 0.9949 - val_loss: 0.0151\n",
      "Epoch 15/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9940 - loss: 0.0175 - val_accuracy: 0.9949 - val_loss: 0.0148\n",
      "Epoch 16/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0167 - val_accuracy: 0.9949 - val_loss: 0.0151\n",
      "Epoch 17/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0165 - val_accuracy: 0.9949 - val_loss: 0.0146\n",
      "Epoch 18/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0172 - val_accuracy: 0.9949 - val_loss: 0.0148\n",
      "Epoch 19/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0167 - val_accuracy: 0.9935 - val_loss: 0.0163\n",
      "Epoch 20/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0172 - val_accuracy: 0.9922 - val_loss: 0.0159\n",
      "Epoch 21/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0175 - val_accuracy: 0.9949 - val_loss: 0.0143\n",
      "Epoch 22/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0169 - val_accuracy: 0.9949 - val_loss: 0.0148\n",
      "Epoch 23/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0169 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 24/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0146\n",
      "Epoch 25/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0164 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 26/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0162 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 27/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 28/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0165 - val_accuracy: 0.9949 - val_loss: 0.0148\n",
      "Epoch 29/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0165 - val_accuracy: 0.9949 - val_loss: 0.0148\n",
      "Epoch 30/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0174 - val_accuracy: 0.9949 - val_loss: 0.0147\n",
      "Epoch 31/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0169 - val_accuracy: 0.9949 - val_loss: 0.0143\n",
      "Epoch 32/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0160 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 33/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0159 - val_accuracy: 0.9949 - val_loss: 0.0146\n",
      "Epoch 34/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0167 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 35/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0159 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "Epoch 36/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0163 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 37/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0159 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "Epoch 38/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0159 - val_accuracy: 0.9949 - val_loss: 0.0140\n",
      "Epoch 39/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0158 - val_accuracy: 0.9949 - val_loss: 0.0148\n",
      "Epoch 40/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "Epoch 41/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0160 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 42/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0164 - val_accuracy: 0.9949 - val_loss: 0.0150\n",
      "Epoch 43/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0163 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 44/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0162 - val_accuracy: 0.9949 - val_loss: 0.0143\n",
      "Epoch 45/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0158 - val_accuracy: 0.9949 - val_loss: 0.0147\n",
      "Epoch 46/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0164 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 47/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0165 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 48/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "Epoch 49/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0164 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 50/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0158 - val_accuracy: 0.9949 - val_loss: 0.0147\n",
      "Epoch 51/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0163 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 52/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0163 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "Epoch 53/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0143\n",
      "Epoch 54/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0154 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 55/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0165 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 56/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0164 - val_accuracy: 0.9949 - val_loss: 0.0148\n",
      "Epoch 57/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0167 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 58/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "Epoch 59/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0162 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 60/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0160 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 61/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0165 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 62/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0164 - val_accuracy: 0.9949 - val_loss: 0.0141\n",
      "Epoch 63/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0165 - val_accuracy: 0.9949 - val_loss: 0.0147\n",
      "Epoch 64/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0159 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 65/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0160 - val_accuracy: 0.9949 - val_loss: 0.0146\n",
      "Epoch 66/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0153 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 67/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0159 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "Epoch 68/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0146\n",
      "Epoch 69/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0158 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "Epoch 70/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0158 - val_accuracy: 0.9949 - val_loss: 0.0147\n",
      "Epoch 71/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0163 - val_accuracy: 0.9949 - val_loss: 0.0147\n",
      "Epoch 72/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0160 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 73/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0160 - val_accuracy: 0.9949 - val_loss: 0.0143\n",
      "Epoch 74/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0156 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 75/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 76/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0166 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "Epoch 77/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0166 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "Epoch 78/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0164 - val_accuracy: 0.9949 - val_loss: 0.0143\n",
      "Epoch 79/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 80/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0155 - val_accuracy: 0.9949 - val_loss: 0.0143\n",
      "Epoch 81/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0155 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "Epoch 82/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0155 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 83/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0162 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 84/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0160 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 85/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0163 - val_accuracy: 0.9949 - val_loss: 0.0143\n",
      "Epoch 86/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0159 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 87/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0152 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 88/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0164 - val_accuracy: 0.9949 - val_loss: 0.0143\n",
      "Epoch 89/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0171 - val_accuracy: 0.9949 - val_loss: 0.0148\n",
      "Epoch 90/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0159 - val_accuracy: 0.9949 - val_loss: 0.0141\n",
      "Epoch 91/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0150\n",
      "Epoch 92/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0166 - val_accuracy: 0.9949 - val_loss: 0.0145\n",
      "Epoch 93/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "Epoch 94/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0159 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 95/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 96/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0168 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 97/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0163 - val_accuracy: 0.9949 - val_loss: 0.0141\n",
      "Epoch 98/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0160 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 99/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0158 - val_accuracy: 0.9949 - val_loss: 0.0144\n",
      "Epoch 100/100\n",
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0161 - val_accuracy: 0.9949 - val_loss: 0.0142\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 570us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for top 2 predictions: 100.00%\n",
      "Models and scaler have been saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('lightning_roulette_results.csv')\n",
    "\n",
    "# Convert Unix timestamp ('when') to datetime\n",
    "df['Datetime'] = pd.to_datetime(df['when'], unit='s')\n",
    "\n",
    "# Extract time-based features from the 'Datetime' column\n",
    "df['Hour'] = df['Datetime'].dt.hour\n",
    "df['Minute'] = df['Datetime'].dt.minute\n",
    "df['Second'] = df['Datetime'].dt.second\n",
    "df['Weekday'] = df['Datetime'].dt.weekday  # 0=Monday, 6=Sunday\n",
    "df['Month'] = df['Datetime'].dt.month\n",
    "\n",
    "# Define helper function to get roulette column (1st, 2nd, or 3rd column)\n",
    "def get_column_from_spin(spin):\n",
    "    if (spin - 1) % 3 == 0:\n",
    "        return 1  # 1st column\n",
    "    elif (spin - 2) % 3 == 0:\n",
    "        return 2  # 2nd column\n",
    "    else:\n",
    "        return 3  # 3rd column\n",
    "\n",
    "# Apply the column extractor to create a column feature\n",
    "df['Column'] = df['result'].apply(get_column_from_spin)\n",
    "\n",
    "# Create target column: the 11th spin's column\n",
    "df['Column 11th Spin'] = df['Column'].shift(-10)\n",
    "\n",
    "# Drop rows where target label (Column 11th Spin) is NaN\n",
    "df = df.dropna(subset=['Column 11th Spin'])\n",
    "\n",
    "# Function to extract categorical features\n",
    "def extract_categorical_features(number):\n",
    "    features = {}\n",
    "    features['even_odd'] = 1 if number % 2 == 0 else 0  # 1 = Even, 0 = Odd\n",
    "    features['high_low'] = 1 if 19 <= number <= 36 else 0  # 1 = High, 0 = Low (1-18)\n",
    "    features['dozen'] = (number - 1) // 12 + 1  # 1 = 1-12, 2 = 13-24, 3 = 25-36\n",
    "    return features\n",
    "\n",
    "# Function to extract previous spins features\n",
    "def extract_previous_spins_features(data, sequence_length=10):\n",
    "    features = {}\n",
    "    if len(data) >= sequence_length:\n",
    "        last_n_spins = data[-sequence_length:]\n",
    "        features['rolling_mean'] = np.mean(last_n_spins)\n",
    "        features['rolling_std'] = np.std(last_n_spins)\n",
    "        features['rolling_min'] = np.min(last_n_spins)\n",
    "        features['rolling_max'] = np.max(last_n_spins)\n",
    "    return features\n",
    "\n",
    "# Create new features based on the result column\n",
    "def create_features(df, sequence_length=10):\n",
    "    categorical_features = df['result'].apply(extract_categorical_features).apply(pd.Series)\n",
    "    \n",
    "    # Create rolling features manually\n",
    "    rolling_features = []\n",
    "    for i in range(sequence_length, len(df)):\n",
    "        # Extract the last sequence_length spins\n",
    "        spins_sequence = df['result'].iloc[i-sequence_length:i]\n",
    "        features = extract_previous_spins_features(spins_sequence, sequence_length)\n",
    "        rolling_features.append(features)\n",
    "    \n",
    "    rolling_features_df = pd.DataFrame(rolling_features)\n",
    "    \n",
    "    # Merge categorical and rolling features\n",
    "    df_features = pd.concat([df.iloc[sequence_length:], categorical_features, rolling_features_df], axis=1)\n",
    "    \n",
    "    # Drop NaN values (shouldn't be any after the rolling features extraction)\n",
    "    df_features = df_features.dropna()\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Apply feature engineering\n",
    "df_features = create_features(df)\n",
    "\n",
    "# Features (we will use result, Hour, Minute, Second, etc.)\n",
    "X = df_features[['result', 'Hour', 'Minute', 'Second', 'Weekday', 'Month', \n",
    "                 'even_odd', 'high_low', 'dozen', \n",
    "                 'rolling_mean', 'rolling_std', 'rolling_min', 'rolling_max']]\n",
    "\n",
    "# Target column: Column for 11th spin (1st, 2nd, or 3rd column)\n",
    "y = df_features['Column 11th Spin']\n",
    "\n",
    "# Adjust labels to zero-indexed (0, 1, 2) for use with sparse categorical crossentropy\n",
    "y = y - 1  # Now it's 0-indexed (0 = 1st column, 1 = 2nd column, 2 = 3rd column)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the deep learning model\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(128, activation='relu')(input_layer)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Output layer (for 11th spin's column)\n",
    "output = Dense(3, activation='softmax')(x)  # Three classes: 0, 1, 2\n",
    "\n",
    "# Define the model\n",
    "deep_model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# Compile the model with sparse categorical crossentropy loss\n",
    "deep_model.compile(optimizer=Adam(), \n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Train the deep learning model\n",
    "deep_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Train additional models (Random Forest, XGBoost, Logistic Regression) for the 11th column\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit these models on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Get soft voting predictions (probabilities)\n",
    "dl_probs = deep_model.predict(X_test)\n",
    "rf_probs = rf_model.predict_proba(X_test)\n",
    "xgb_probs = xgb_model.predict_proba(X_test)\n",
    "lr_probs = lr_model.predict_proba(X_test)\n",
    "\n",
    "# Combine all models' probabilities using soft voting (average)\n",
    "avg_probs = (dl_probs + rf_probs + xgb_probs + lr_probs) / 4\n",
    "\n",
    "# For each test sample, find the top 2 most likely columns\n",
    "top_2_predictions = np.argsort(avg_probs, axis=1)[:, -2:]  # Get indices of top 2 predictions for each sample\n",
    "\n",
    "# Convert to 1-indexed labels\n",
    "top_2_predictions = top_2_predictions + 1\n",
    "\n",
    "# Calculate accuracy: Check if the true column is in the top 2 predicted columns\n",
    "correct_predictions = 0\n",
    "for i in range(len(y_test)):\n",
    "    if (y_test.iloc[i] + 1) in top_2_predictions[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(y_test)\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Accuracy for top 2 predictions: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save models\n",
    "deep_model.save('deep_model.h5')  # Save the deep learning model\n",
    "joblib.dump(rf_model, 'rf_model.pkl')\n",
    "joblib.dump(xgb_model, 'xgb_model.pkl')\n",
    "joblib.dump(lr_model, 'lr_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')  # Save the scaler for future use\n",
    "\n",
    "print(\"Models and scaler have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b078901-1e9f-4124-8d3f-2367b83db271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Second</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>even_odd</th>\n",
       "      <th>high_low</th>\n",
       "      <th>dozen</th>\n",
       "      <th>rolling_mean</th>\n",
       "      <th>rolling_std</th>\n",
       "      <th>rolling_min</th>\n",
       "      <th>rolling_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22.3</td>\n",
       "      <td>7.457211</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.5</td>\n",
       "      <td>7.392564</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24.8</td>\n",
       "      <td>5.963221</td>\n",
       "      <td>16.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24.9</td>\n",
       "      <td>5.821512</td>\n",
       "      <td>17.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>23.3</td>\n",
       "      <td>6.856384</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499975</th>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.9</td>\n",
       "      <td>8.607555</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499976</th>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18.6</td>\n",
       "      <td>9.971961</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499977</th>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>9.187491</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499978</th>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>10.000500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499979</th>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>10.952625</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499970 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        result  Hour  Minute  Second  Weekday  Month  even_odd  high_low  \\\n",
       "10        19.0  16.0     1.0     9.0      6.0    1.0         0         1   \n",
       "11         8.0  16.0     0.0    25.0      6.0    1.0         1         0   \n",
       "12        16.0  15.0    59.0    41.0      6.0    1.0         1         0   \n",
       "13        28.0  15.0    58.0    53.0      6.0    1.0         1         1   \n",
       "14        17.0  15.0    58.0     5.0      6.0    1.0         0         0   \n",
       "...        ...   ...     ...     ...      ...    ...       ...       ...   \n",
       "499975    16.0  15.0    18.0    31.0      6.0    1.0         1         0   \n",
       "499976    31.0  15.0    17.0    41.0      6.0    1.0         0         1   \n",
       "499977    21.0  15.0    16.0    57.0      6.0    1.0         0         1   \n",
       "499978    22.0  15.0    16.0    12.0      6.0    1.0         1         1   \n",
       "499979    28.0  15.0    15.0    29.0      6.0    1.0         1         1   \n",
       "\n",
       "        dozen  rolling_mean  rolling_std  rolling_min  rolling_max  \n",
       "10          2          22.3     7.457211          8.0         35.0  \n",
       "11          1          22.5     7.392564          8.0         35.0  \n",
       "12          2          24.8     5.963221         16.0         35.0  \n",
       "13          3          24.9     5.821512         17.0         35.0  \n",
       "14          2          23.3     6.856384         12.0         35.0  \n",
       "...       ...           ...          ...          ...          ...  \n",
       "499975      2          19.9     8.607555          8.0         33.0  \n",
       "499976      3          18.6     9.971961          3.0         33.0  \n",
       "499977      2          17.7     9.187491          3.0         33.0  \n",
       "499978      2          18.7    10.000500          3.0         33.0  \n",
       "499979      3          16.8    10.952625          3.0         33.0  \n",
       "\n",
       "[499970 rows x 13 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "382e1126-a739-4c3d-8052-3a0d88ac65d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10        2.0\n",
       "11        0.0\n",
       "12        1.0\n",
       "13        2.0\n",
       "14        0.0\n",
       "         ... \n",
       "499975    2.0\n",
       "499976    0.0\n",
       "499977    0.0\n",
       "499978    2.0\n",
       "499979    2.0\n",
       "Name: Column 11th Spin, Length: 499970, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c461f-d247-4876-af09-d7ab7579216e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
